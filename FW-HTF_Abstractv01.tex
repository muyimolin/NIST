\pagebreak

\begin{center}
	{\Large \bf FW-HTF Theme 2: \textbf{Extending and Developing the Dexterous and Coordinated Motor Skills of Industrial Workers through Physical and Cognitive Human-Robot Synergy}}\\
    \vspace{4pt}
% 	\renewcommand{\baselinestretch}{1}
   	{\large PI: Zhi Li (Worcester Polytechnic Institute)\\
    Co-PI: Jacob Rosen (University of California, Los Angles)}
   	% \vspace{4pt}
    % {\large Worcester Polytechnic Institute}
\end{center}

\vspace{1 em}

\paragraph*{\Large Project Summary} 
Tele-operated robotic systems extend a human worker's physical capabilities to perform manufacturing and maintenance tasks in remote, inaccessible, and/or hazardous environments. Complex and risk-sensitive tasks that require human-level manipulation dexterity and decision-making intelligence are infeasible through autonomous control, yet can be accomplished under direct (tele)operation. To freely and efficiently control their remote surrogates, human workers need to devote significant efforts to learn the motion and perception mapping defined by the (tele)operation interface. To address these needs, we propose to investigate the physical and cognitive interactions between human workers and (tele)operation interfaces, and develop a user interface to support intuitive robot control and multi-modality cognitive augmentation. 

Our proposed project aims to (a) reduce the teleoperation control effort in dexterous and coordinated manipulation tasks, (b) facilitate novice workers to acquire the fine motor skills for operating complicate robotic systems to work on various manufacturing tasks, (c) propose novel worker training infrastructure and methodologies improve the skills and well-being of industrial workers, and (d) create safe, comfortable, and remotely accessible industrial job opportunities. We propose research objectives with the emphases on \textit{science and technology}, as well as \textit{education and social-economy}. Our Science and technology objectives aim to investigate theories and technologies that (1) Shift the boundary between direct teleoperation and autonomous control based on the physical and mental status of the operator, (2) synthesize and convert sensory information to improve cognitive situation-awareness, and improve cognitive and physical skills of the operator, (3) Infer human teleoperator's contextual intent based on the knowledge of manipulation tasks and human motions, in order to automate appropriate low-level robot actions. Our education and social-economy objective aims to (1) Integrate ``cloud wisdom'' in terms cognitive augmentation into the collaborative decision-making and motor learning process among multiple intelligence agents (human experts and AIs) through a democratic or weighted voting system, (2) Study the effect of cognitive-augmentation human-robot interface on industrial worker skill acquisition and mental/physical demands in training processes, (3) Develop novel training methodologies and infrastructure at home and in workplace, and (4) Investigate the social-economical impacts of such technology on small and large industries, and on societal job opportunity shift and regional and national job distribution.  

\vspace{0.5 em}

\paragraph*{\Large Intellectual Merit}
This project addresses how multi-modality cognitive feedback affects human motor behavior and motor learning process. Specifically, we will experimentally study in teleoperated manipulation tasks that requires simultaneous control of multiple robot components, such as loco-manipulation, bimanual coordination, arm-hand-finger coordination. For \textbf{expert workers}, we focuses on \textit{how human decision-making and task operation can be affected by single- and multi-modality cognitive feedback, and investigate methods for intuitive and integrated representation of task information and cognitive feedback}, to reduce an expert worker's the physical and mental efforts. For \textbf{novice workers}, we will focus on \textit{how multi-modality cognitive feedback affects the explicit and implicit learning of dexterous and coordinated manipulation motor skills}, as well as \textit{when and how to provide high-level/abstract cognitive feedback (e.g., verbal/text instructions, numbers, etc.) and low-level intuitive cognitive feedback (e.g., colors, shapes, sounds, tactile and forces, etc.) to facilitate the interactive and associated explicit and implicit motor learning}. Our proposed research is unique for it will develop a unified framework that integrate the model-based and model-less robot learning methodologies to reveal the underlying principles of the associated implicit and explicit human motor learning processes. The enhanced understanding of the cognitive and physical interactions between human worker and teleoperation interfaces further leads to novel techniques for user-adaptive cognitive augmentation and decision-making assistance, which leverages ``cloud wisdom'' and adjust the human-robot control efforts based on a human worker's intents, physical/mental states, and skill level. 

% to robot learning that acquire motion and task knowledge through  (e.g., reinforcement learning with explicit reward function v.s. learning through convolutional neural network). Inspired by how human can develop situational awareness and motor skills through intuitive and abstract cognitive feedback and augmentation, we will further develop novel robot teaching methodologies for that leverage human-guided robot interactions with environments and demonstrations/critiques from human teachers. 


% By investigating the underlying principles of the cognitive and physical interaction between the human worker and teleoperation interfaces, we will advance the technologies for user-adaptive cognitive augmentation to facilitate novice workers to build their situational awareness and master the motion mapping between the input interfaces and their physical embodiments in the tasks. Towards the seamless integration of human and (tele-)operated robotic systems, our research will further investigate shared-autonomous control methods for adjusting the human-robot control efforts based on human worker's skill level and physical/mental states. 

% We will also investigate how to utilize the teleoperation interface as an efficient robot teaching interface, to relieve workers from repetitive low-level teleoperation. 


% Towards the seamless integration of human and (tele-)operated robotic systems, we will further investigate shared-autonomous control methods for adjusting the human-robot control efforts based on human worker's skill level and physical/mental states. We will also investigate how to utilize the teleoperation interface as an efficient robot teaching interface, to relieve workers from repetitive low-level teleoperation. 

% This project aims to discover the new knowledge of how multi-modality cognitive feedback affects explicit and implicit learning processes of coordinated manipulation motor skills, and develop novel methodologies for 

% how this knowledge can be used to (1) 

% develop robot control interface that integrates intuitive and abstract multi-modality  to provide user-adaptive   

% Specifically, we will experimentally study in teleoperated manipulation tasks, how human decision-making and task operation can be affected by single- and multi-modality cognitive feedback, and investigate methods for intuitive and integrated representation of task information and cognitive feedback, to reduce an expert worker's the physical and mental efforts. For novice workers, we will focus on how multi-modality cognitive feedback affects the explicit and implicit learning of dexterous and coordinated manipulation motor skills, as well as when and how to provide high-level/abstract cognitive feedback (e.g., verbal/text instructions, numbers, etc.) and low-level intuitive cognitive feedback (e.g., colors, shapes, sounds, tactile and forces, etc.) to facilitate the interactive and associated explicit and implicit motro learning. By investigating the underlying principles of the interaction between the human worker and teleoperation interfaces, we will develop user-adaptive cognitive augmentation to facilitate novice workers to build their situational awareness and master the motion mapping between the input interfaces and their physical embodiments in the tasks. Towards the seamless integration of human and (tele-)operated robotic systems, we will further investigate shared-autonomous control methods for adjusting the human-robot control efforts based on human worker's skill level and physical/mental states. We will also investigate how to utilize the teleoperation interface as an efficient robot teaching interface, to relieve workers from repetitive low-level teleoperation. 



\vspace{0.5 em}

\paragraph*{\Large Broader Impacts}
Our research will directly and primarily benefit industrial workers that operate tele-manufacturing robotic system, and will have boarder impacts on a wide range of workers that need to master the skill of operating complex human-machine interfaces for direct control and robot teaching, such as tele-surgery, tele-nursing, and shared-autonomous driving. By improving the usability of teleoperation interface, we aim to improve the availability of healthcare, industrial, and social service labor, and provide capable surrogates for military and medical personnels in tedious, repetitive, and dangerous tasks. It will also lead towards affordable robotic solutions can provide assistance and job opportunities to wider populations. 

% Our research will also synergize with graduate and undergraduate education for students from engineering, medical, and nursing schools, and will actively engage K-12 students and the general public. 

% Through robot-mediated interactions, develops robot motion intelligence in a multi-agent, highly-interactive context. 



% to navigate in cluttered human environments and perform a wide variety of dexterous manipulation tasks with minimal human control. Our key idea is to develop a unified framework for lifelong learning and fast, context-based intent and in simultaneous multi-lateral physical human-robot interactions. In such scenarios, the nursing robot participates in a patient-caring task, while learning when and how to intervene in the robot-mediated collaboration between its remote teleoperator and on-site human partners. By observing human experts, the nursing robot will also establish hierarchical knowledge of natural coordinated human motions and human-human interactions, and metrics for evaluating task performance and motion capabilities. Such motion knowledge and metrics will be used to evaluate the level of skills of novice teleoperators, patients and partner nurses, and adjust the level of assistance provided to maintain nursing task performance and fluency of human-robot collaboration. 

  
% \vspace{0.5 em}

% \paragraph*{\Large Intellectual Merit}
% Our proposal aims to address the need for \textit{\textbf{customizable robot motion intelligence}}, and to \textit{\textbf{lower the barriers}} for medical personnel to synergize with tele-robotic technologies. Our proposed framework enables a tele-robotic system to develop and evolve its contextual motion intelligence through lifelong interactions with human experts, and apply its motion intelligence to provide user-adaptive assistance to reduce learning and operation effort for novice teleoperators.   



% \vspace{0.5 em}

% \paragraph*{\Large Broader Impacts}
% This project envisions broader impacts on a wide range of mobile humanoid robots for medical, industrial, and social service tasks. Our research efforts will enable these robots to interact simultaneously and physically with both the teleoperator and end users, and reconcile their intents to achieve natural, fluent, and intimate collaboration.
% % PM: I changed this to singular "barrier" to make the claim a bit less grand? Feel free to change back if desired.
% We aim to remove a major barrier that prevents robots from integrating into human society as capable and socially acceptable peers. By improving the usability of dexterous robotic manipulators under direct teleoperation and shared-autonomous control, this project may also lead to improved availability of healthcare, industrial, and social service labor, and provide surrogates for military and medical personnel for tedious, repetitive, and dangerous tasks. It will lead towards affordable robotic solutions for hospital and home care that can provide long-term assistance to aging and disabled populations. Our research will also synergize with graduate and undergraduate education for students from engineering, medical, and nursing schools, and will actively engage K-12 students and the general public. 

% \vspace{2 em}
% \noindent
% \textbf{Keywords} --- Customizability, Lowering Barriers, Learning, Human-Robot Interaction, Medical